{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#pip install -U imbalanced-learn scikit-learn\n",
    "#!pip install imbalanced-learn\n",
    "#!pip install -U scikit-learn\n",
    "##!pip install -U imbalanced-learn\n",
    "#!pip uninstall imbalanced-learn\n",
    "#!pip list\n",
    "#!pip install imbalanced-learn\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacfb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd2ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hohih\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40537201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66717a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a28b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c57191",
   "metadata": {},
   "source": [
    "The goal is to be able to predict which child is going to get a IVH based on values prior to a IVH.\n",
    "However cutting the data to the day of IVH reduces the number of data, and maybe they do contain valuable info. \n",
    "\n",
    "Approach:\n",
    "Try to remove all datapoints after a IVH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12d77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and set IVH level to binary 0 or 1\n",
    "data = pd.read_csv('Table_preterm_2019_articleMLM.csv', sep=';')\n",
    "#data['grad IVH'] = data['grad IVH'].replace([1,2,3,4],1)\n",
    "data['grad IVH'] = data['grad IVH'].replace([1,2,3,4],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d522b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (6537, 18)\n",
      "Shape of y: (6537,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['grad IVH', 'day of IVH', 'Day befor/after IVH', '#Patient'], axis=1)  # Replace 'target_column_name' with the actual column name of the labels\n",
    "y = data['grad IVH']\n",
    "\n",
    "'''X = data.iloc[:, :-1].values\n",
    "X = data.take([5], axis=1)\n",
    "y = data.iloc[:, 5].values'''\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "# Convert the scaled features back to a DataFrame\n",
    "X = pd.DataFrame( X_scaled, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70558272-f0ae-41c5-bb1a-8104a770a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e37f0db-41d7-41f2-835a-4115172303c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.0.0 Requires-Python >=3.6, <3.9; 0.1.1 Requires-Python >=3.6, <3.9; 0.1.2 Requires-Python >=3.6, <3.9; 0.1.3 Requires-Python >=3.6, <3.9; 0.10.0 Requires-Python >=3.8, <3.11; 0.2.0 Requires-Python >=3.6, <3.9; 0.2.1 Requires-Python >=3.6, <3.9; 0.2.2 Requires-Python >=3.6, <3.9; 0.2.3 Requires-Python >=3.6, <3.9; 0.2.4 Requires-Python >=3.6, <3.9; 0.3.0 Requires-Python >=3.6, <3.9; 0.3.1 Requires-Python >=3.6, <3.9; 0.3.2 Requires-Python >=3.6, <3.9; 0.3.3 Requires-Python >=3.6, <3.9; 0.3.4 Requires-Python >=3.6, <3.9; 0.4.0 Requires-Python >=3.6, <3.9; 0.5.0 Requires-Python >=3.6, <3.9; 0.6.0 Requires-Python >=3.6, <3.9; 0.6.1 Requires-Python >=3.6, <3.9; 0.7.0 Requires-Python >=3.6, <3.9; 0.7.1 Requires-Python >=3.6, <3.9; 0.8.0 Requires-Python >=3.6, <3.9; 0.9.0 Requires-Python >=3.8, <3.11; 1.0.0 Requires-Python >=3.8, <3.11; 1.0.1 Requires-Python >=3.8, <3.11; 1.1.0 Requires-Python >=3.9, <3.11; 1.2.0 Requires-Python >=3.9, <3.11; 1.3.0 Requires-Python >=3.9, <3.11; 1.3.1 Requires-Python >=3.9, <3.11; 1.3.2 Requires-Python >=3.9, <3.11\n",
      "ERROR: Could not find a version that satisfies the requirement ydata-synthetic (from versions: none)\n",
      "ERROR: No matching distribution found for ydata-synthetic\n"
     ]
    }
   ],
   "source": [
    "pip install ydata-synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91591f63-dedb-4a1b-80b9-55c03f0947e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b790d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes = 2\n",
    "unique_patients = np.unique(data.iloc[:, 0].values)\n",
    "X_list = [X[data.iloc[:, 0].values == patient] for patient in unique_patients]\n",
    "y_list = [np.array(y[data.iloc[:, 0].values == patient]) for patient in unique_patients]\n",
    "#y_list = np.array(y_list)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_list, y_list, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f37634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ls = [X_train[i] for i in range(len(X_train))]\n",
    "X_train= pd.concat(X_train_ls, ignore_index=True)\n",
    "X_test_ls = [X_test[i] for i in range(len(X_test))]\n",
    "X_test= pd.concat(X_test_ls, ignore_index=True)\n",
    "\n",
    "#X_train= pd.concat(X_train_ls, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62959055",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ls = [y_train[i].tolist() for i in range(len(y_train))]\n",
    "y_train = sum(y_train_ls, [])\n",
    "y_test_ls = [y_test[i].tolist() for i in range(len(y_test))]\n",
    "y_test = sum(y_test_ls, [])\n",
    "#type(y_train_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82266dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59c1347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fe1db90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {}\n",
      "Best Accuracy:  0.5540400665300425\n"
     ]
    }
   ],
   "source": [
    "# Define the AdaBoost classifier\n",
    "adaboost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    #'n_estimators': [7, 10, 50],\n",
    "    #'learning_rate': [0.01, 0.05, 0.1],\n",
    "    #'estimator__max_depth': [1, 2, 3]\n",
    "    #estimator__min_samples_split\": [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(adaboost, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef447879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting Accuracy: 0.7608695652173914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Stacking\\nestimators = [\\n    (\\'bagging\\', BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)),\\n    (\\'boosting\\', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42))\\n]\\nstacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\\nstacking_model.fit(X_train, y_train)\\nstacking_predictions = stacking_model.predict(X_test)\\nstacking_accuracy = accuracy_score(y_test, stacking_predictions)\\nprint(\"Stacking Accuracy:\", stacking_accuracy)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Bagging\n",
    "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "bagging_predictions = bagging_model.predict(X_test)\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
    "print(\"Bagging Accuracy:\", bagging_accuracy)\n",
    "'''\n",
    "# Boosting\n",
    "boosting_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "boosting_model.fit(X_train, y_train)\n",
    "boosting_predictions = boosting_model.predict(X_test)\n",
    "boosting_accuracy = accuracy_score(y_test, boosting_predictions)\n",
    "print(\"Boosting Accuracy:\", boosting_accuracy)\n",
    "\n",
    "'''# Stacking\n",
    "estimators = [\n",
    "    ('bagging', BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)),\n",
    "    ('boosting', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42))\n",
    "]\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking_model.fit(X_train, y_train)\n",
    "stacking_predictions = stacking_model.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
    "print(\"Stacking Accuracy:\", stacking_accuracy)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bad3cde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7608695652173914\n",
      "Precision: 0.75\n",
      "Recall: 0.6428571428571429\n",
      "F1-score: 0.6923076923076924\n",
      "AUC-ROC: 0.7443257676902537\n",
      "Shit results\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = boosting_predictions# rfe.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"AUC-ROC:\", roc_auc)\n",
    "print(\"Shit results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8279844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[362  66]\n",
      " [110 198]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "236d795d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5679347826086957\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "num_classes=2\n",
    "# Set the parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Set the objective function for multi-class classification\n",
    "    'num_class': num_classes,  # Set the number of classes\n",
    "    'eval_metric': 'merror'  # Set the evaluation metric\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_rounds = 100  # Set the number of boosting rounds\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# Convert the predicted labels to integers\n",
    "y_pred = y_pred.astype(int)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab2ff07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6385869565217391\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d97f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc5db130",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (0,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(num_classes)[y_test]\n\u001b[0;32m      3\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m X_train \u001b[38;5;241m+\u001b[39m X_test])\n\u001b[1;32m----> 4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mpad(seq, ((\u001b[38;5;241m0\u001b[39m, max_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(seq)), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m X_train])\n\u001b[0;32m      5\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mpad(seq, ((\u001b[38;5;241m0\u001b[39m, max_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(seq)), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m X_test])\n",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(num_classes)[y_test]\n\u001b[0;32m      3\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m X_train \u001b[38;5;241m+\u001b[39m X_test])\n\u001b[1;32m----> 4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m X_train])\n\u001b[0;32m      5\u001b[0m X_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mpad(seq, ((\u001b[38;5;241m0\u001b[39m, max_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(seq)), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m X_test])\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\IVH\\lib\\site-packages\\numpy\\lib\\arraypad.py:744\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`pad_width` must be of integral type.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;66;03m# Broadcast to shape (array.ndim, 2)\u001b[39;00m\n\u001b[1;32m--> 744\u001b[0m pad_width \u001b[38;5;241m=\u001b[39m \u001b[43m_as_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mode):\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;66;03m# Old behavior: Use user-supplied function with np.apply_along_axis\u001b[39;00m\n\u001b[0;32m    748\u001b[0m     function \u001b[38;5;241m=\u001b[39m mode\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\IVH\\lib\\site-packages\\numpy\\lib\\arraypad.py:518\u001b[0m, in \u001b[0;36m_as_pairs\u001b[1;34m(x, ndim, as_index)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain negative values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    516\u001b[0m \u001b[38;5;66;03m# Converting the array with `tolist` seems to improve performance\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# when iterating and indexing the result (see usage in `pad`)\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\IVH\\lib\\site-packages\\numpy\\lib\\stride_tricks.py:413\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[1;34m(array, shape, subok)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array, shape, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;124;03m           [1, 2, 3]])\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreadonly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\IVH\\lib\\site-packages\\numpy\\lib\\stride_tricks.py:349\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[1;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall elements of broadcast shape must be non-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    347\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    348\u001b[0m extras \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 349\u001b[0m it \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnditer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrefs_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzerosize_ok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextras\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreadonly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitershape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m it:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;66;03m# never really has writebackifcopy semantics\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     broadcast \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mitviews[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (0,2)"
     ]
    }
   ],
   "source": [
    "y_train = np.eye(num_classes)[y_train]\n",
    "y_test = np.eye(num_classes)[y_test]\n",
    "max_length = max([len(seq) for seq in X_train + X_test])\n",
    "X_train = np.array([np.pad(seq, ((0, max_length - len(seq)), (0, 0)), 'constant') for seq in X_train])\n",
    "X_test = np.array([np.pad(seq, ((0, max_length - len(seq)), (0, 0)), 'constant') for seq in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bae376ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\envs\\IVH\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m70\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(max_length, \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m)))  \u001b[38;5;66;03m# 50 is the number of LSTM units, adjust as needed\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(70, input_shape=(max_length, X_train.shape[2])))  # 50 is the number of LSTM units, adjust as needed\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4253c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a46ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a66f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_test[0].squeeze()), y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feedforward neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert the one-hot encoded labels back to original labels\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef241ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d879cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
